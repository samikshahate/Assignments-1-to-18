{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9635d59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:43:25.881343Z",
     "start_time": "2022-06-24T21:43:24.444490Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8bca3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:43:59.068736Z",
     "start_time": "2022-06-24T21:43:58.993740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"gas_turbines.csv\")\n",
    "df=df.iloc[:,[7,0,1,2]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a416c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:44:18.099946Z",
     "start_time": "2022-06-24T21:44:18.010949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEY</th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>134.188464</td>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.829717</td>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100.170000</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>133.780000</td>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>140.895000</td>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>174.610000</td>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TEY            AT           AP            AH\n",
       "count  15039.000000  15039.000000  15039.00000  15039.000000\n",
       "mean     134.188464     17.764381   1013.19924     79.124174\n",
       "std       15.829717      7.574323      6.41076     13.793439\n",
       "min      100.170000      0.522300    985.85000     30.344000\n",
       "25%      127.985000     11.408000   1008.90000     69.750000\n",
       "50%      133.780000     18.186000   1012.80000     82.266000\n",
       "75%      140.895000     23.862500   1016.90000     90.043500\n",
       "max      174.610000     34.929000   1034.20000    100.200000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb21ae66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:44:25.819919Z",
     "start_time": "2022-06-24T21:44:25.789953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEY    0\n",
       "AT     0\n",
       "AP     0\n",
       "AH     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04cfe8a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:44:34.179334Z",
     "start_time": "2022-06-24T21:44:34.163181Z"
    }
   },
   "outputs": [],
   "source": [
    "x=df.iloc[:,1:5]\n",
    "y=df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a77bd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:44:43.365967Z",
     "start_time": "2022-06-24T21:44:43.325323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH\n",
       "0      6.8594  1007.9  96.799\n",
       "1      6.7850  1008.4  97.118\n",
       "2      6.8977  1008.8  95.939\n",
       "3      7.0569  1009.2  95.249\n",
       "4      7.3978  1009.7  95.150\n",
       "...       ...     ...     ...\n",
       "15034  9.0301  1005.6  98.460\n",
       "15035  7.8879  1005.9  99.093\n",
       "15036  7.2647  1006.3  99.496\n",
       "15037  7.0060  1006.8  99.008\n",
       "15038  6.9279  1007.2  97.533\n",
       "\n",
       "[15039 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "908565d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:44:46.709093Z",
     "start_time": "2022-06-24T21:44:46.698094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        114.70\n",
       "1        114.72\n",
       "2        114.71\n",
       "3        114.72\n",
       "4        114.72\n",
       "          ...  \n",
       "15034    111.61\n",
       "15035    111.78\n",
       "15036    110.19\n",
       "15037    110.74\n",
       "15038    111.58\n",
       "Name: TEY, Length: 15039, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3bb810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:51:08.975300Z",
     "start_time": "2022-06-24T21:44:56.356806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1008/1008 [==============================] - 4s 3ms/step - loss: -67.1178 - accuracy: 0.0000e+00 - val_loss: -131.6601 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -202.5880 - accuracy: 0.0000e+00 - val_loss: -263.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -337.8508 - accuracy: 0.0000e+00 - val_loss: -395.4978 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -473.1011 - accuracy: 0.0000e+00 - val_loss: -527.3593 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -608.3403 - accuracy: 0.0000e+00 - val_loss: -659.2587 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -743.5865 - accuracy: 0.0000e+00 - val_loss: -791.1411 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -878.8475 - accuracy: 0.0000e+00 - val_loss: -923.0566 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -1014.1456 - accuracy: 0.0000e+00 - val_loss: -1054.9861 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -1149.4805 - accuracy: 0.0000e+00 - val_loss: -1186.9624 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1284.7480 - accuracy: 0.0000e+00 - val_loss: -1318.8353 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -1419.9780 - accuracy: 0.0000e+00 - val_loss: -1450.6920 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -1555.2819 - accuracy: 0.0000e+00 - val_loss: -1582.6652 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1690.5203 - accuracy: 0.0000e+00 - val_loss: -1714.5057 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -1825.7986 - accuracy: 0.0000e+00 - val_loss: -1846.4634 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -1961.0868 - accuracy: 0.0000e+00 - val_loss: -1978.3406 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -2096.3191 - accuracy: 0.0000e+00 - val_loss: -2110.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2231.5876 - accuracy: 0.0000e+00 - val_loss: -2242.1162 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2366.8276 - accuracy: 0.0000e+00 - val_loss: -2373.9976 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -2502.1072 - accuracy: 0.0000e+00 - val_loss: -2505.9268 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -2637.4199 - accuracy: 0.0000e+00 - val_loss: -2637.8792 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -2772.7053 - accuracy: 0.0000e+00 - val_loss: -2769.7876 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -2907.9631 - accuracy: 0.0000e+00 - val_loss: -2901.6824 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3043.2170 - accuracy: 0.0000e+00 - val_loss: -3033.5667 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3178.4883 - accuracy: 0.0000e+00 - val_loss: -3165.4746 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -3313.7488 - accuracy: 0.0000e+00 - val_loss: -3297.3838 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3449.0176 - accuracy: 0.0000e+00 - val_loss: -3429.2844 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3584.2561 - accuracy: 0.0000e+00 - val_loss: -3561.1360 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3719.5271 - accuracy: 0.0000e+00 - val_loss: -3693.0630 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3854.8159 - accuracy: 0.0000e+00 - val_loss: -3824.9922 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3990.0706 - accuracy: 0.0000e+00 - val_loss: -3956.8640 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4125.3618 - accuracy: 0.0000e+00 - val_loss: -4088.8035 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -4260.6191 - accuracy: 0.0000e+00 - val_loss: -4220.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4395.8872 - accuracy: 0.0000e+00 - val_loss: -4352.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4531.1353 - accuracy: 0.0000e+00 - val_loss: -4484.4614 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4666.4004 - accuracy: 0.0000e+00 - val_loss: -4616.4048 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4801.6821 - accuracy: 0.0000e+00 - val_loss: -4748.3057 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4937.0029 - accuracy: 0.0000e+00 - val_loss: -4880.2700 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -5072.2695 - accuracy: 0.0000e+00 - val_loss: -5012.1646 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -5207.5176 - accuracy: 0.0000e+00 - val_loss: -5144.0405 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -5342.7866 - accuracy: 0.0000e+00 - val_loss: -5275.9263 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -5478.0571 - accuracy: 0.0000e+00 - val_loss: -5407.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -5613.3447 - accuracy: 0.0000e+00 - val_loss: -5539.7822 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -5748.6104 - accuracy: 0.0000e+00 - val_loss: -5671.6821 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -5883.8848 - accuracy: 0.0000e+00 - val_loss: -5803.5791 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -6019.1191 - accuracy: 0.0000e+00 - val_loss: -5935.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -6154.4004 - accuracy: 0.0000e+00 - val_loss: -6067.3799 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -6289.6733 - accuracy: 0.0000e+00 - val_loss: -6199.2949 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -6424.9712 - accuracy: 0.0000e+00 - val_loss: -6331.2002 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -6560.2578 - accuracy: 0.0000e+00 - val_loss: -6463.1460 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -6695.4888 - accuracy: 0.0000e+00 - val_loss: -6594.9751 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -6830.7417 - accuracy: 0.0000e+00 - val_loss: -6726.8867 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -6965.9951 - accuracy: 0.0000e+00 - val_loss: -6858.7739 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7101.2593 - accuracy: 0.0000e+00 - val_loss: -6990.6929 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7236.5146 - accuracy: 0.0000e+00 - val_loss: -7122.5776 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7371.8047 - accuracy: 0.0000e+00 - val_loss: -7254.5010 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7507.0840 - accuracy: 0.0000e+00 - val_loss: -7386.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7642.3516 - accuracy: 0.0000e+00 - val_loss: -7518.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7777.5869 - accuracy: 0.0000e+00 - val_loss: -7650.1899 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -7912.8862 - accuracy: 0.0000e+00 - val_loss: -7782.1328 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8048.1816 - accuracy: 0.0000e+00 - val_loss: -7914.0439 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -8183.4014 - accuracy: 0.0000e+00 - val_loss: -8045.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -8318.6865 - accuracy: 0.0000e+00 - val_loss: -8177.8594 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8453.9619 - accuracy: 0.0000e+00 - val_loss: -8309.7129 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8589.2529 - accuracy: 0.0000e+00 - val_loss: -8441.6914 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8724.5576 - accuracy: 0.0000e+00 - val_loss: -8573.5928 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8859.8193 - accuracy: 0.0000e+00 - val_loss: -8705.5107 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -8995.0850 - accuracy: 0.0000e+00 - val_loss: -8837.4033 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9130.3418 - accuracy: 0.0000e+00 - val_loss: -8969.2920 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -9265.6250 - accuracy: 0.0000e+00 - val_loss: -9101.2148 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -9400.9014 - accuracy: 0.0000e+00 - val_loss: -9233.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -9536.1836 - accuracy: 0.0000e+00 - val_loss: -9365.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -9671.3828 - accuracy: 0.0000e+00 - val_loss: -9496.8828 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9806.6514 - accuracy: 0.0000e+00 - val_loss: -9628.7959 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -9941.9102 - accuracy: 0.0000e+00 - val_loss: -9760.6738 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10077.1807 - accuracy: 0.0000e+00 - val_loss: -9892.6113 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10212.4648 - accuracy: 0.0000e+00 - val_loss: -10024.5029 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10347.7412 - accuracy: 0.0000e+00 - val_loss: -10156.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10482.9893 - accuracy: 0.0000e+00 - val_loss: -10288.2861 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10618.2441 - accuracy: 0.0000e+00 - val_loss: -10420.2070 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -10753.5146 - accuracy: 0.0000e+00 - val_loss: -10552.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -10888.8037 - accuracy: 0.0000e+00 - val_loss: -10684.0645 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -11024.1045 - accuracy: 0.0000e+00 - val_loss: -10815.9746 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11159.3643 - accuracy: 0.0000e+00 - val_loss: -10947.8398 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11294.6035 - accuracy: 0.0000e+00 - val_loss: -11079.7168 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -11429.8203 - accuracy: 0.0000e+00 - val_loss: -11211.5693 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -11565.0811 - accuracy: 0.0000e+00 - val_loss: -11343.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -11700.3799 - accuracy: 0.0000e+00 - val_loss: -11475.4590 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -11835.6768 - accuracy: 0.0000e+00 - val_loss: -11607.3604 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -11970.9707 - accuracy: 0.0000e+00 - val_loss: -11739.2754 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: -12106.1963 - accuracy: 0.0000e+00 - val_loss: -11871.1602 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12241.4873 - accuracy: 0.0000e+00 - val_loss: -12003.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12376.7764 - accuracy: 0.0000e+00 - val_loss: -12134.9844 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12512.0420 - accuracy: 0.0000e+00 - val_loss: -12266.8770 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12647.3125 - accuracy: 0.0000e+00 - val_loss: -12398.7832 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -12782.5605 - accuracy: 0.0000e+00 - val_loss: -12530.6738 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -12917.8389 - accuracy: 0.0000e+00 - val_loss: -12662.5898 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13053.1582 - accuracy: 0.0000e+00 - val_loss: -12794.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13188.4297 - accuracy: 0.0000e+00 - val_loss: -12926.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13323.6680 - accuracy: 0.0000e+00 - val_loss: -13058.3408 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -13458.9697 - accuracy: 0.0000e+00 - val_loss: -13190.3047 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13594.2734 - accuracy: 0.0000e+00 - val_loss: -13322.2129 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13729.5225 - accuracy: 0.0000e+00 - val_loss: -13454.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -13864.7451 - accuracy: 0.0000e+00 - val_loss: -13585.9258 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14000.0098 - accuracy: 0.0000e+00 - val_loss: -13717.8564 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14135.2803 - accuracy: 0.0000e+00 - val_loss: -13849.7588 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14270.5166 - accuracy: 0.0000e+00 - val_loss: -13981.6357 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14405.7646 - accuracy: 0.0000e+00 - val_loss: -14113.5020 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14541.0293 - accuracy: 0.0000e+00 - val_loss: -14245.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14676.2939 - accuracy: 0.0000e+00 - val_loss: -14377.3223 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14811.5762 - accuracy: 0.0000e+00 - val_loss: -14509.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -14946.8633 - accuracy: 0.0000e+00 - val_loss: -14641.1836 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15082.1514 - accuracy: 0.0000e+00 - val_loss: -14773.0635 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15217.3740 - accuracy: 0.0000e+00 - val_loss: -14904.9395 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15352.6562 - accuracy: 0.0000e+00 - val_loss: -15036.8555 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15487.9111 - accuracy: 0.0000e+00 - val_loss: -15168.7676 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15623.1660 - accuracy: 0.0000e+00 - val_loss: -15300.6553 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15758.4648 - accuracy: 0.0000e+00 - val_loss: -15432.5527 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -15893.7305 - accuracy: 0.0000e+00 - val_loss: -15564.4727 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16028.9873 - accuracy: 0.0000e+00 - val_loss: -15696.3838 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16164.2783 - accuracy: 0.0000e+00 - val_loss: -15828.2861 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16299.5361 - accuracy: 0.0000e+00 - val_loss: -15960.1777 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16434.7891 - accuracy: 0.0000e+00 - val_loss: -16092.0947 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16570.0508 - accuracy: 0.0000e+00 - val_loss: -16223.9795 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16705.3379 - accuracy: 0.0000e+00 - val_loss: -16355.9043 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16840.6172 - accuracy: 0.0000e+00 - val_loss: -16487.7871 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -16975.8926 - accuracy: 0.0000e+00 - val_loss: -16619.7227 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17111.1816 - accuracy: 0.0000e+00 - val_loss: -16751.6113 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17246.4590 - accuracy: 0.0000e+00 - val_loss: -16883.5840 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17381.7285 - accuracy: 0.0000e+00 - val_loss: -17015.4609 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17516.9688 - accuracy: 0.0000e+00 - val_loss: -17147.3555 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17652.2246 - accuracy: 0.0000e+00 - val_loss: -17279.2129 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17787.4902 - accuracy: 0.0000e+00 - val_loss: -17411.1426 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -17922.7402 - accuracy: 0.0000e+00 - val_loss: -17542.9922 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -18058.0137 - accuracy: 0.0000e+00 - val_loss: -17674.9648 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -18193.3145 - accuracy: 0.0000e+00 - val_loss: -17806.8672 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18328.5996 - accuracy: 0.0000e+00 - val_loss: -17938.7793 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18463.8477 - accuracy: 0.0000e+00 - val_loss: -18070.6582 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18599.0996 - accuracy: 0.0000e+00 - val_loss: -18202.5703 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18734.3320 - accuracy: 0.0000e+00 - val_loss: -18334.4434 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -18869.6113 - accuracy: 0.0000e+00 - val_loss: -18466.3145 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19004.8496 - accuracy: 0.0000e+00 - val_loss: -18598.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19140.0762 - accuracy: 0.0000e+00 - val_loss: -18730.0645 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19275.3242 - accuracy: 0.0000e+00 - val_loss: -18861.9551 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19410.6367 - accuracy: 0.0000e+00 - val_loss: -18993.9277 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19545.9121 - accuracy: 0.0000e+00 - val_loss: -19125.7988 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19681.1250 - accuracy: 0.0000e+00 - val_loss: -19257.6836 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19816.4238 - accuracy: 0.0000e+00 - val_loss: -19389.6328 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -19951.7129 - accuracy: 0.0000e+00 - val_loss: -19521.5234 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -20086.9883 - accuracy: 0.0000e+00 - val_loss: -19653.4629 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: -20222.2480 - accuracy: 0.0000e+00 - val_loss: -19785.3184 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=3,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1,  kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history= model.fit(x, y,validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324697df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:52:17.972138Z",
     "start_time": "2022-06-24T21:52:16.661393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1s 2ms/step - loss: -20123.4102 - accuracy: 0.0000e+00\n",
      "accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x, y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d95449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:52:29.020903Z",
     "start_time": "2022-06-24T21:52:29.003902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a12147e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:53:15.193914Z",
     "start_time": "2022-06-24T21:53:14.397833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbuklEQVR4nO3de5QV5Z3u8e8jooAgIIhyDWiIkRgD2CKOnjk6SsJFQcccRw2JmjNBEz3BWTER4sTEWefiWZMYY6ISNWQwOl7iJTKKyiVgkqOogHhBMKCjoQGVoCCgqODv/FHVZNPZ3V0Uvbs23c9nrV69633fqvrtht1P110RgZmZ2e7ap+gCzMxs7+QAMTOzXBwgZmaWiwPEzMxycYCYmVkuDhAzM8vFAWKWkaR/k/Q/M459TdKpla7JrEgOEDMzy8UBYtbGSNq36BqsdXCAWKuS7jr6tqTnJW2V9AtJh0h6RNJmSXMldS8ZP17SMkkbJS2QdGRJ3zBJS9L57gY61FvXaZKWpvM+IenojDWOk/SspHclrZb0g3r9J6bL25j2X5C2d5T0I0mvS9ok6Q9p20mSasv8HE5NX/9A0r2Sbpf0LnCBpBGSnkzXsU7SzyTtVzL/ZyTNkfS2pDclfVfSoZLek9SjZNwxktZLap/lvVvr4gCx1ugsYBTwKeB04BHgu0BPkv/z3wSQ9CngTuAy4GBgFvAfkvZLf5n+BvgVcBDw63S5pPMOB6YDFwE9gJ8DMyXtn6G+rcBXgG7AOODrks5IlzsgrfenaU1DgaXpfD8EjgH+Jq3pO8DHGX8mE4B703XeAewA/onkZ3I8cArwjbSGLsBc4FGgD/BJYF5EvAEsAM4uWe5E4K6I+ChjHdaKOECsNfppRLwZEWuA3wNPRcSzEfEB8AAwLB33D8DDETEn/QX4Q6AjyS/okUB74LqI+Cgi7gWeKVnH14CfR8RTEbEjImYAH6TzNSoiFkTECxHxcUQ8TxJi/zXt/hIwNyLuTNe7ISKWStoH+CowOSLWpOt8In1PWTwZEb9J1/l+RCyOiIURsT0iXiMJwLoaTgPeiIgfRcS2iNgcEU+lfTNIQgNJ7YBzSULW2iAHiLVGb5a8fr/MdOf0dR/g9bqOiPgYWA30TfvWxK53G3295PUngG+lu4A2StoI9E/na5Sk4yTNT3f9bAIuJtkSIF3GK2Vm60myC61cXxar69XwKUkPSXoj3a31vzPUAPAgMETSYSRbeZsi4umcNdlezgFibdlakiAAQJJIfnmuAdYBfdO2OgNKXq8G/ldEdCv56hQRd2ZY778DM4H+EdEVmAbUrWc1cHiZef4MbGugbyvQqeR9tCPZ/VWq/m23bwJWAIMj4kCSXXxN1UBEbAPuIdlS+jLe+mjTHCDWlt0DjJN0SnoQ+Fsku6GeAJ4EtgPflLSvpL8HRpTMewtwcbo1IUkHpAfHu2RYbxfg7YjYJmkEcF5J3x3AqZLOTtfbQ9LQdOtoOnCtpD6S2kk6Pj3m8kegQ7r+9sA/A00di+kCvAtskfRp4OslfQ8Bh0q6TNL+krpIOq6k/zbgAmA8cHuG92utlAPE2qyIeJlkf/5PSf7CPx04PSI+jIgPgb8n+UX5DsnxkvtL5l1EchzkZ2n/qnRsFt8A/kXSZuAqkiCrW+6fgLEkYfY2yQH0z6XdlwMvkByLeRv4v8A+EbEpXeatJFtPW4Fdzsoq43KS4NpMEoZ3l9SwmWT31OnAG8BK4OSS/v9HcvB+SXr8xNoo+YFSZra7JP0W+PeIuLXoWqw4DhAz2y2SjgXmkBzD2Vx0PVYc78Iys8wkzSC5RuQyh4d5C8TMzHLxFoiZmeXSpm6q1rNnzxg4cGDRZZiZ7VUWL17854iof21R2wqQgQMHsmjRoqLLMDPbq0h6vVy7d2GZmVkuDhAzM8vFAWJmZrm0qWMg5Xz00UfU1taybdu2okupqA4dOtCvXz/at/dzf8ysebT5AKmtraVLly4MHDiQXW+82npEBBs2bKC2tpZBgwYVXY6ZtRJtfhfWtm3b6NGjR6sNDwBJ9OjRo9VvZZlZy2rzAQK06vCo0xbeo5m1LAeImZnl4gAp2MaNG7nxxht3e76xY8eycePG5i/IzCwjB0jBGgqQHTt2NDrfrFmz6NatW4WqMjNrWps/C6toU6ZM4ZVXXmHo0KG0b9+ezp0707t3b5YuXcpLL73EGWecwerVq9m2bRuTJ09m0qRJwF9uy7JlyxbGjBnDiSeeyBNPPEHfvn158MEH6dixY8HvzMxaOwdIiav/YxkvrX23WZc5pM+BfP/0zzTYf8011/Diiy+ydOlSFixYwLhx43jxxRd3nm47ffp0DjroIN5//32OPfZYzjrrLHr06LHLMlauXMmdd97JLbfcwtlnn819993HxIkTm/V9mJnV5wCpMiNGjNjlWo3rr7+eBx54AIDVq1ezcuXKvwqQQYMGMXToUACOOeYYXnvttZYq18zaMAdIica2FFrKAQccsPP1ggULmDt3Lk8++SSdOnXipJNOKnstx/7777/zdbt27Xj//fdbpFYza9t8EL1gXbp0YfPm8k8G3bRpE927d6dTp06sWLGChQsXtnB1ZmYN8xZIwXr06MEJJ5zAUUcdRceOHTnkkEN29o0ePZpp06Zx9NFHc8QRRzBy5MgCKzUz21WbeiZ6TU1N1H+g1PLlyznyyCMLqqhltaX3ambNR9LiiKip3+5dWGZmlosDxMzMcnGAmJlZLg4QMzPLxQFiZma5OEDMzCwXB0jB8t7OHeC6667jvffea+aKzMyycYAUzAFiZnurQq9ElzQa+AnQDrg1Iq6p16+0fyzwHnBBRCwp6W8HLALWRMRpLVZ4Myq9nfuoUaPo1asX99xzDx988AFnnnkmV199NVu3buXss8+mtraWHTt28L3vfY8333yTtWvXcvLJJ9OzZ0/mz59f9FsxszamsABJf/nfAIwCaoFnJM2MiJdKho0BBqdfxwE3pd/rTAaWAwc2S1GPTIE3XmiWRe106GdhzDUNdpfezn327Nnce++9PP3000QE48eP53e/+x3r16+nT58+PPzww0Byj6yuXbty7bXXMn/+fHr27Nm8NZuZZVDkLqwRwKqIeDUiPgTuAibUGzMBuC0SC4FuknoDSOoHjANubcmiK2n27NnMnj2bYcOGMXz4cFasWMHKlSv57Gc/y9y5c7niiiv4/e9/T9euXYsu1cys0F1YfYHVJdO17Lp10dCYvsA64DrgO0CXxlYiaRIwCWDAgAGNV9TIlkJLiAimTp3KRRdd9Fd9ixcvZtasWUydOpXPf/7zXHXVVQVUaGb2F0VugahMW/07O5YdI+k04K2IWNzUSiLi5oioiYiagw8+OE+dFVV6O/cvfOELTJ8+nS1btgCwZs0a3nrrLdauXUunTp2YOHEil19+OUuWLPmrec3MWlqRWyC1QP+S6X7A2oxjvgiMlzQW6AAcKOn2iNjrnuNaejv3MWPGcN5553H88ccD0LlzZ26//XZWrVrFt7/9bfbZZx/at2/PTTfdBMCkSZMYM2YMvXv39kF0M2txhd3OXdK+wB+BU4A1wDPAeRGxrGTMOOBSkrOwjgOuj4gR9ZZzEnB5lrOwfDv3tvNezaz5NHQ798K2QCJiu6RLgcdITuOdHhHLJF2c9k8DZpGExyqS03gvLKpeMzPbVaHXgUTELJKQKG2bVvI6gEuaWMYCYEEFyjMzs0b4SnSSs59au7bwHs2sZbX5AOnQoQMbNmxo1b9gI4INGzbQoUOHoksxs1ak0F1Y1aBfv37U1tayfv36okupqA4dOtCvX7+iyzCzVqTNB0j79u0ZNGhQ0WWYme112vwuLDMzy8cBYmZmuThAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuThAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuThAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuRQaIJJGS3pZ0ipJU8r0S9L1af/zkoan7f0lzZe0XNIySZNbvnozs7atsACR1A64ARgDDAHOlTSk3rAxwOD0axJwU9q+HfhWRBwJjAQuKTOvmZlVUJFbICOAVRHxakR8CNwFTKg3ZgJwWyQWAt0k9Y6IdRGxBCAiNgPLgb4tWbyZWVtXZID0BVaXTNfy1yHQ5BhJA4FhwFPNX6KZmTWkyABRmbbYnTGSOgP3AZdFxLtlVyJNkrRI0qL169fnLtbMzHZVZIDUAv1LpvsBa7OOkdSeJDzuiIj7G1pJRNwcETURUXPwwQc3S+FmZlZsgDwDDJY0SNJ+wDnAzHpjZgJfSc/GGglsioh1kgT8AlgeEde2bNlmZgawb1Erjojtki4FHgPaAdMjYpmki9P+acAsYCywCngPuDCd/QTgy8ALkpambd+NiFkt+BbMzNo0RdQ/7NB61dTUxKJFi4ouw8xsryJpcUTU1G/3lehmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuThAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuThAzMwsl0wBIuk+SeMkOXDMzAzIvgVyE3AesFLSNZI+XcGazMxsL5ApQCJibkR8CRgOvAbMkfSEpAvTZ5ObmVkbk3mXlKQewAXAPwLPAj8hCZQ5FanMzMyqWqZnoku6H/g08Cvg9IhYl3bdLcnPiDUza4MyBQjws4j4bbmOcs/JNTOz1i/rLqwjJXWrm5DUXdI3KlOSmZntDbIGyNciYmPdRES8A3ytIhWZmdleIWuA7CNJdROS2gH7VaYkMzPbG2Q9BvIYcI+kaUAAFwOPVqwqMzOrelkD5ArgIuDrgIDZwK2VKsrMzKpfpgCJiI9Jrka/qbLlmJnZ3iLrdSCDgf8DDAE61LVHxGEVqsvMzKpc1oPovyTZ+tgOnAzcRnJRoZmZtVFZA6RjRMwDFBGvR8QPgL+rXFlmZlbtsh5E35beyn2lpEuBNUCvypVlZmbVLusWyGVAJ+CbwDHAROD8CtVkZmZ7gSYDJL1o8OyI2BIRtRFxYUScFREL93TlkkZLelnSKklTyvRL0vVp//OShmed18zMKqvJAImIHcAxpVeiN4c0mG4AxpCc3XWupCH1ho0BBqdfk0hPI844r5mZVVDWYyDPAg9K+jWwta4xIu7fg3WPAFZFxKsAku4CJgAvlYyZANwWEQEslNRNUm9gYIZ5m83CG79Gl43LK7FoM7MWsbnbkYz8xi3NusysAXIQsIFdz7wKYE8CpC+wumS6Fjguw5i+GecFQNIkkq0XBgwYsAflmplZqaxXol9YgXWX2yUWGcdkmTdpjLgZuBmgpqam7JimNHdqm5m1BlmvRP8lZX5BR8RX92DdtUD/kul+wNqMY/bLMK+ZmVVQ1tN4HwIeTr/mAQcCW/Zw3c8AgyUNkrQfcA4ws96YmcBX0rOxRgKb0sfpZpnXzMwqKOsurPtKpyXdCczdkxVHxPb0osTHgHbA9IhYJunitH8aMAsYC6wC3gMubGzePanHzMx2j5ITnHZzJukI4OGI+GTzl1Q5NTU1sWjRoqLLMDPbq0haHBE19duzHgPZzK7HQN4geUaImZm1UVl3YXWpdCFmZrZ3yXQQXdKZkrqWTHeTdEbFqjIzs6qX9Sys70fEprqJiNgIfL8iFZmZ2V4ha4CUG5f1KnYzM2uFsgbIIknXSjpc0mGSfgwsrmRhZmZW3bIGyP8APgTuBu4B3gcuqVRRZmZW/bKehbUV8DM3zMxsp6xnYc2R1K1kurukxypWlZmZVb2su7B6pmdeARAR7+BnopuZtWlZA+RjSTsfpiFpIA3cPt3MzNqGrKfiXgn8QdLj6fTfkj6kyczM2qasB9EflVRDEhpLgQdJzsQyM7M2KuvNFP8RmEzy4KalwEjgSXZ9xK2ZmbUhWY+BTAaOBV6PiJOBYcD6ilVlZmZVL2uAbIuIbQCS9o+IFcARlSvLzMyqXdaD6LXpdSC/AeZIegc/g9zMrE3LehD9zPTlDyTNB7oCj1asKjMzq3q7fUfdiHi86VFmZtbaZT0GYmZmtgsHiJmZ5eIAMTOzXBwgZmaWiwPEzMxycYCYmVkuDhAzM8vFAWJmZrk4QMzMLBcHiJmZ5eIAMTOzXAoJEEkHSZojaWX6vXsD40ZLelnSKklTStr/VdIKSc9LeiC9U7CZmbWgorZApgDzImIwMC+d3oWkdsANwBhgCHCupCFp9xzgqIg4GvgjMLVFqjYzs52KCpAJwIz09QzgjDJjRgCrIuLViPgQuCudj4iYHRHb03ELSR61a2ZmLaioADkkItYBpN97lRnTF1hdMl2bttX3VeCRZq/QzMwatdvPA8lK0lzg0DJdV2ZdRJm2qLeOK4HtwB2N1DEJmAQwYMCAjKs2M7OmVCxAIuLUhvokvSmpd0Ssk9QbeKvMsFqgf8l0P0oeoyvpfOA04JSICBoQETcDNwPU1NQ0OM7MzHZPUbuwZgLnp6/PBx4sM+YZYLCkQZL2A85J50PSaOAKYHxEvNcC9ZqZWT1FBcg1wChJK4FR6TSS+kiaBZAeJL8UeAxYDtwTEcvS+X8GdAHmSFoqaVpLvwEzs7auYruwGhMRG4BTyrSvBcaWTM8CZpUZ98mKFmhmZk3ylehmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuThAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuThAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuThAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuThAzMwsFweImZnlUkiASDpI0hxJK9Pv3RsYN1rSy5JWSZpSpv9ySSGpZ+WrNjOzUkVtgUwB5kXEYGBeOr0LSe2AG4AxwBDgXElDSvr7A6OAP7VIxWZmtouiAmQCMCN9PQM4o8yYEcCqiHg1Ij4E7krnq/Nj4DtAVLBOMzNrQFEBckhErANIv/cqM6YvsLpkujZtQ9J4YE1EPNfUiiRNkrRI0qL169fveeVmZgbAvpVasKS5wKFluq7MuogybSGpU7qMz2dZSETcDNwMUFNT460VM7NmUrEAiYhTG+qT9Kak3hGxTlJv4K0yw2qB/iXT/YC1wOHAIOA5SXXtSySNiIg3mu0NmJlZo4rahTUTOD99fT7wYJkxzwCDJQ2StB9wDjAzIl6IiF4RMTAiBpIEzXCHh5lZyyoqQK4BRklaSXIm1TUAkvpImgUQEduBS4HHgOXAPRGxrKB6zcysnortwmpMRGwATinTvhYYWzI9C5jVxLIGNnd9ZmbWNF+JbmZmuThAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuThAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHJxgJiZWS4OEDMzy8UBYmZmuThAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHJxgJiZWS4OEDMzy0URUXQNLUbSeuD1nLP3BP7cjOVUgmtsHq5xz1V7feAad8cnIuLg+o1tKkD2hKRFEVFTdB2NcY3NwzXuuWqvD1xjc/AuLDMzy8UBYmZmuThAsru56AIycI3NwzXuuWqvD1zjHvMxEDMzy8VbIGZmlosDxMzMcnGAZCBptKSXJa2SNKUK6ukvab6k5ZKWSZqcth8kaY6klen37lVQaztJz0p6qBprlNRN0r2SVqQ/z+OrsMZ/Sv+dX5R0p6QORdcoabqktyS9WNLWYE2Spqafn5clfaHAGv81/bd+XtIDkrpVW40lfZdLCkk9i6yxMQ6QJkhqB9wAjAGGAOdKGlJsVWwHvhURRwIjgUvSmqYA8yJiMDAvnS7aZGB5yXS11fgT4NGI+DTwOZJaq6ZGSX2BbwI1EXEU0A44pwpq/DdgdL22sjWl/zfPAT6TznNj+rkqosY5wFERcTTwR2BqFdaIpP7AKOBPJW1F1dggB0jTRgCrIuLViPgQuAuYUGRBEbEuIpakrzeT/NLrm9Y1Ix02AzijkAJTkvoB44BbS5qrpkZJBwJ/C/wCICI+jIiNVFGNqX2BjpL2BToBaym4xoj4HfB2veaGapoA3BURH0TEfwKrSD5XLV5jRMyOiO3p5EKgX7XVmPox8B2g9CynQmpsjAOkaX2B1SXTtWlbVZA0EBgGPAUcEhHrIAkZoFeBpQFcR/Ih+LikrZpqPAxYD/wy3c12q6QDqqnGiFgD/JDkL9F1wKaImF1NNZZoqKZq/Qx9FXgkfV01NUoaD6yJiOfqdVVNjXUcIE1TmbaqOPdZUmfgPuCyiHi36HpKSToNeCsiFhddSyP2BYYDN0XEMGArxe9S20V6HGECMAjoAxwgaWKxVe22qvsMSbqSZFfwHXVNZYa1eI2SOgFXAleV6y7TVujP0QHStFqgf8l0P5JdCIWS1J4kPO6IiPvT5jcl9U77ewNvFVUfcAIwXtJrJLv9/k7S7VRXjbVAbUQ8lU7fSxIo1VTjqcB/RsT6iPgIuB/4myqrsU5DNVXVZ0jS+cBpwJfiLxfCVUuNh5P8sfBc+tnpByyRdCjVU+NODpCmPQMMljRI0n4kB7FmFlmQJJHst18eEdeWdM0Ezk9fnw882NK11YmIqRHRLyIGkvzMfhsRE6muGt8AVks6Im06BXiJKqqRZNfVSEmd0n/3U0iOeVVTjXUaqmkmcI6k/SUNAgYDTxdQH5JGA1cA4yPivZKuqqgxIl6IiF4RMTD97NQCw9P/q1VR4y4iwl9NfAFjSc7YeAW4sgrqOZFk0/V5YGn6NRboQXL2y8r0+0FF15rWexLwUPq6qmoEhgKL0p/lb4DuVVjj1cAK4EXgV8D+RdcI3ElyTOYjkl9y/72xmkh2y7wCvAyMKbDGVSTHEeo+N9OqrcZ6/a8BPYussbEv38rEzMxy8S4sMzPLxQFiZma5OEDMzCwXB4iZmeXiADEzs1wcIGZ7CUkn1d3V2KwaOEDMzCwXB4hZM5M0UdLTkpZK+nn6TJQtkn4kaYmkeZIOTscOlbSw5PkU3dP2T0qaK+m5dJ7D08V31l+eX3JHenW6WSEcIGbNSNKRwD8AJ0TEUGAH8CXgAGBJRAwHHge+n85yG3BFJM+neKGk/Q7ghoj4HMm9r9al7cOAy0ieTXMYyT3HzAqxb9EFmLUypwDHAM+kGwcdSW4q+DFwdzrmduB+SV2BbhHxeNo+A/i1pC5A34h4ACAitgGky3s6ImrT6aXAQOAPFX9XZmU4QMyal4AZETF1l0bpe/XGNXYPocZ2S31Q8noH/gxbgbwLy6x5zQO+KKkX7HxO+CdIPmtfTMecB/whIjYB70j6L2n7l4HHI3m2S62kM9Jl7J8+J8KsqvivF7NmFBEvSfpnYLakfUjusnoJycOqPiNpMbCJ5DgJJLc9n5YGxKvAhWn7l4GfS/qXdBn/rQXfhlkmvhuvWQuQtCUiOhddh1lz8i4sMzPLxVsgZmaWi7dAzMwsFweImZnl4gAxM7NcHCBmZpaLA8TMzHL5/45UnFnhzAYeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db92c688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:53:25.239972Z",
     "start_time": "2022-06-24T21:53:25.189115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.320107e-16</td>\n",
       "      <td>-1.925280e-14</td>\n",
       "      <td>1.844983e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.276462e+00</td>\n",
       "      <td>-4.266288e+00</td>\n",
       "      <td>-3.536594e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.392292e-01</td>\n",
       "      <td>-6.706510e-01</td>\n",
       "      <td>-6.796337e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.566605e-02</td>\n",
       "      <td>-6.227861e-02</td>\n",
       "      <td>2.277844e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.051309e-01</td>\n",
       "      <td>5.772924e-01</td>\n",
       "      <td>7.916582e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.266234e+00</td>\n",
       "      <td>3.275970e+00</td>\n",
       "      <td>1.528011e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2\n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04\n",
       "mean  -2.320107e-16 -1.925280e-14  1.844983e-16\n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00\n",
       "min   -2.276462e+00 -4.266288e+00 -3.536594e+00\n",
       "25%   -8.392292e-01 -6.706510e-01 -6.796337e-01\n",
       "50%    5.566605e-02 -6.227861e-02  2.277844e-01\n",
       "75%    8.051309e-01  5.772924e-01  7.916582e-01\n",
       "max    2.266234e+00  3.275970e+00  1.528011e+00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(x)\n",
    "X_standardized = a.transform(x)\n",
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d3833a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T21:53:32.833907Z",
     "start_time": "2022-06-24T21:53:32.817925Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=3, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\\\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d43871c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T22:32:21.610814Z",
     "start_time": "2022-06-24T21:54:06.147894Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_18296/73594983.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  20.0s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  20.2s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  18.5s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  16.9s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time=  16.1s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 1.3min\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 1.3min\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 1.3min\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 2.3min\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 2.4min\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 2.4min\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 2.3min\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time= 2.3min\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=   8.9s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=   7.9s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=   7.9s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=   8.0s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=   7.8s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  35.9s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  36.1s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  35.6s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  35.6s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time=  35.7s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.6min\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.6min\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.5min\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.8min\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 1.9min\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   6.2s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   6.2s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   6.0s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   6.1s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time=   6.1s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  26.7s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  26.0s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  25.2s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  25.6s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=  23.2s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  50.7s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  46.0s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  50.4s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  42.1s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time=  39.9s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aa4e319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T22:33:22.678548Z",
     "start_time": "2022-06-24T22:33:22.658544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1af052e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T22:33:57.555001Z",
     "start_time": "2022-06-24T22:33:57.498979Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 3,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 3,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "355626fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T22:41:14.101800Z",
     "start_time": "2022-06-24T22:34:26.294856Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_18296/2472349717.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  10.7s\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  12.2s\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=  11.8s\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=   8.8s\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=   7.9s\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=   8.2s\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=   7.7s\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=   7.9s\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=   8.3s\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time=   7.8s\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=   7.9s\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=   7.0s\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=  10.4s\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=   9.6s\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time=   8.0s\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=   9.5s\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=   8.6s\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=   8.0s\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=   9.0s\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time=   9.2s\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=   9.2s\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=  10.6s\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=   9.0s\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=   7.7s\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=   9.0s\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=   7.7s\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=   8.0s\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=   8.9s\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=   8.5s\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time=   7.8s\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=   8.3s\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  10.3s\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=  10.1s\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=   7.7s\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time=   8.9s\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=   8.4s\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=   8.4s\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=   8.0s\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=   8.6s\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time=   7.8s\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=   8.7s\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=   8.2s\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=   8.0s\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=   9.1s\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=   7.9s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b6611bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T22:42:18.814031Z",
     "start_time": "2022-06-24T22:42:18.790032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af74658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T22:42:27.094612Z",
     "start_time": "2022-06-24T22:42:27.071103Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 3,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 3,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fedfce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T22:52:18.570603Z",
     "start_time": "2022-06-24T22:43:07.565994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_18296/2150382326.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=  11.8s\n",
      "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=  10.0s\n",
      "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=  10.1s\n",
      "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=   8.8s\n",
      "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.000 total time=   9.1s\n",
      "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=   9.9s\n",
      "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=   8.1s\n",
      "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=  10.0s\n",
      "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=   8.0s\n",
      "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.000 total time=   9.2s\n",
      "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=  10.0s\n",
      "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   9.7s\n",
      "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   9.4s\n",
      "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   9.5s\n",
      "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.000 total time=   9.4s\n",
      "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=   9.0s\n",
      "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=   8.6s\n",
      "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=   9.4s\n",
      "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=   9.5s\n",
      "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.000 total time=   8.2s\n",
      "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=   8.8s\n",
      "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=   8.5s\n",
      "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=   8.9s\n",
      "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=   8.9s\n",
      "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.000 total time=   9.4s\n",
      "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   9.2s\n",
      "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   8.6s\n",
      "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   8.5s\n",
      "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   9.0s\n",
      "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.000 total time=   9.2s\n",
      "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=   8.3s\n",
      "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=   9.0s\n",
      "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=   7.3s\n",
      "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=   8.5s\n",
      "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.000 total time=   8.3s\n",
      "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=   7.7s\n",
      "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=   9.1s\n",
      "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=   9.0s\n",
      "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=   8.2s\n",
      "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.000 total time=   8.4s\n",
      "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   8.4s\n",
      "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   8.9s\n",
      "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   8.7s\n",
      "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   8.9s\n",
      "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.000 total time=   8.1s\n",
      "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=   8.9s\n",
      "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=   8.8s\n",
      "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=   7.5s\n",
      "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=   8.6s\n",
      "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.000 total time=  10.3s\n",
      "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=   9.0s\n",
      "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=   8.6s\n",
      "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=   8.5s\n",
      "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=   8.6s\n",
      "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.000 total time=   8.9s\n",
      "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   8.7s\n",
      "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   8.7s\n",
      "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   8.7s\n",
      "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   8.2s\n",
      "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.000 total time=   8.7s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99225dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T22:52:47.446345Z",
     "start_time": "2022-06-24T22:52:47.431810Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 3,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2335a142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T23:00:02.365707Z",
     "start_time": "2022-06-24T22:53:09.580922Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_18296/1328446193.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.000 total time=  11.4s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.000 total time=   9.7s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.000 total time=   9.5s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.000 total time=   9.2s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.000 total time=   8.9s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.000 total time=   8.7s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.000 total time=   9.1s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.000 total time=  10.0s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.000 total time=   9.3s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.000 total time=   8.4s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.000 total time=   8.5s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.000 total time=   8.6s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.000 total time=   7.8s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.000 total time=  10.0s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.000 total time=   8.6s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.000 total time=   8.1s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.000 total time=   8.3s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.000 total time=   8.7s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.000 total time=   8.7s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.000 total time=   8.9s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.000 total time=   9.0s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.000 total time=   8.6s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.000 total time=   8.9s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.000 total time=   9.2s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.000 total time=   8.9s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.000 total time=   8.1s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.000 total time=   9.1s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.000 total time=   9.1s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.000 total time=   8.0s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.000 total time=   8.2s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.000 total time=   8.3s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.000 total time=   8.1s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.000 total time=   8.6s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.000 total time=   9.1s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.000 total time=   7.6s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.000 total time=   9.2s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.000 total time=   7.8s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.000 total time=   9.1s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.000 total time=   8.8s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.000 total time=   9.2s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.000 total time=   9.3s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.000 total time=   9.2s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.000 total time=   7.8s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.000 total time=   8.7s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.000 total time=   9.5s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "685c9bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T23:00:35.093124Z",
     "start_time": "2022-06-24T23:00:35.067948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61e22354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T23:00:39.023060Z",
     "start_time": "2022-06-24T23:00:39.002198Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,input_dim = 3,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 3,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    \n",
    "    adam = Adam(lr = 0.01) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d419432e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T23:02:57.017351Z",
     "start_time": "2022-06-24T23:01:06.108949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp/ipykernel_18296/641616389.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 7s 2ms/step\n",
      "0.00013298756566261055\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
    "\n",
    "\n",
    "model.fit(X_standardized,y)\n",
    "\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "print(accuracy_score(y_predict.round(),y.round()))"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "neural networks assignment gas turbines",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
